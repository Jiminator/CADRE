job is starting on gpua061.delta.ncsa.illinois.edu
Using fixed seeds: 5497 58475 94707
SEED: 5497
Loading drug dataset...
Hyperparameters:
Namespace(seed=5497, is_train=True, input_dir='data/input', output_dir='data/output', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=True, init_gene_emb=True, scheduler='onecycle', shuffle=False, omic='exp', use_attention=False, use_cntx_attn=False, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.6, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=False, alpha=0.6, gamma=2.0, adam=False, exp_size=3000, mut_size=1000, cnv_size=1000, omc_size=3000, drg_size=260, train_size=676, test_size=170)
HIDDEN EMBEDDING SIZE: 200
USING RELU
USING PRETRAING EMBEDDINGS
DROPOUT RATE: 0.6
USING HIDDEN LAYER
INITIALIZING SGD OPTIMIZER
Training...
INITIALIZING ONE CYCLE
Batch size: 8
Train dataset size (samples): 676
Batches per epoch: 85
[0,0] | tst acc:49.3, f1:15.3, auc:47.2 | trn acc:50.6, f1:36.6, auc:50.6 | loss:0.884
[1,348] | tst acc:51.7, f1:16.6, auc:48.0 | trn acc:51.1, f1:39.3, auc:51.0 | loss:0.875
[3,20] | tst acc:54.6, f1:21.8, auc:57.8 | trn acc:53.0, f1:41.0, auc:53.2 | loss:0.827
[4,368] | tst acc:54.6, f1:18.7, auc:55.9 | trn acc:55.2, f1:42.8, auc:55.9 | loss:0.780
[6,40] | tst acc:55.7, f1:19.1, auc:54.5 | trn acc:57.8, f1:43.9, auc:58.9 | loss:0.733
[7,388] | tst acc:60.0, f1:23.4, auc:62.6 | trn acc:60.5, f1:46.5, auc:62.1 | loss:0.691
[9,60] | tst acc:63.5, f1:25.8, auc:61.7 | trn acc:63.4, f1:48.7, auc:65.3 | loss:0.653
[10,408] | tst acc:66.4, f1:27.4, auc:67.3 | trn acc:66.2, f1:51.1, auc:68.4 | loss:0.621
[12,80] | tst acc:66.8, f1:30.9, auc:76.4 | trn acc:69.0, f1:53.8, auc:71.2 | loss:0.595
[13,428] | tst acc:68.3, f1:29.3, auc:72.8 | trn acc:71.2, f1:56.2, auc:73.7 | loss:0.573
[15,100] | tst acc:72.1, f1:36.0, auc:78.0 | trn acc:73.1, f1:57.9, auc:75.5 | loss:0.555
[16,448] | tst acc:72.7, f1:35.2, auc:77.3 | trn acc:75.0, f1:60.2, auc:77.5 | loss:0.538
[18,120] | tst acc:74.7, f1:37.0, auc:80.7 | trn acc:76.2, f1:61.8, auc:78.7 | loss:0.528
[19,468] | tst acc:73.6, f1:35.3, auc:78.4 | trn acc:77.4, f1:63.1, auc:79.7 | loss:0.519
[21,140] | tst acc:74.0, f1:35.7, auc:81.1 | trn acc:78.2, f1:64.4, auc:80.6 | loss:0.511
[22,488] | tst acc:75.5, f1:38.5, auc:82.1 | trn acc:78.8, f1:64.9, auc:81.3 | loss:0.504
[24,160] | tst acc:76.0, f1:38.9, auc:81.3 | trn acc:79.4, f1:65.9, auc:82.0 | loss:0.498
[25,508] | tst acc:76.9, f1:41.1, auc:82.6 | trn acc:79.7, f1:66.4, auc:82.4 | loss:0.495
[27,180] | tst acc:76.2, f1:38.4, auc:79.6 | trn acc:80.1, f1:66.6, auc:82.7 | loss:0.491
[28,528] | tst acc:76.9, f1:41.1, auc:80.9 | trn acc:80.4, f1:67.2, auc:83.3 | loss:0.487
[30,200] | tst acc:76.0, f1:40.2, auc:84.4 | trn acc:80.6, f1:67.5, auc:83.4 | loss:0.486
[31,548] | tst acc:76.9, f1:40.4, auc:83.1 | trn acc:80.7, f1:67.6, auc:83.7 | loss:0.484
[33,220] | tst acc:78.6, f1:44.3, auc:83.4 | trn acc:80.8, f1:68.0, auc:83.9 | loss:0.483
[34,568] | tst acc:77.3, f1:39.5, auc:80.7 | trn acc:81.0, f1:68.2, auc:84.1 | loss:0.481
[36,240] | tst acc:76.9, f1:41.8, auc:83.0 | trn acc:81.3, f1:68.3, auc:84.4 | loss:0.478
[37,588] | tst acc:77.9, f1:42.9, auc:82.2 | trn acc:81.0, f1:68.1, auc:84.3 | loss:0.480
[39,260] | tst acc:77.3, f1:42.2, auc:84.0 | trn acc:81.3, f1:68.5, auc:84.6 | loss:0.477
[40,608] | tst acc:77.9, f1:42.3, auc:82.6 | trn acc:81.2, f1:68.5, auc:84.6 | loss:0.478
[42,280] | tst acc:77.7, f1:42.7, auc:83.8 | trn acc:81.2, f1:68.4, auc:84.7 | loss:0.478
[43,628] | tst acc:78.2, f1:43.2, auc:83.9 | trn acc:81.3, f1:68.6, auc:84.7 | loss:0.477
[45,300] | tst acc:78.2, f1:43.2, auc:83.9 | trn acc:81.4, f1:68.7, auc:84.8 | loss:0.476
[46,648] | tst acc:78.8, f1:43.9, auc:83.7 | trn acc:81.4, f1:68.8, auc:85.0 | loss:0.476
[48,320] | tst acc:78.2, f1:43.2, auc:82.5 | trn acc:81.6, f1:68.9, auc:85.1 | loss:0.474
[49,668] | tst acc:77.5, f1:41.8, auc:83.4 | trn acc:81.2, f1:68.5, auc:84.8 | loss:0.477
[51,340] | tst acc:77.9, f1:42.9, auc:83.4 | trn acc:81.5, f1:69.0, auc:85.2 | loss:0.474
[53,12] | tst acc:77.7, f1:42.7, auc:84.5 | trn acc:81.3, f1:68.5, auc:84.7 | loss:0.477
[54,360] | tst acc:77.9, f1:42.9, auc:82.9 | trn acc:81.5, f1:68.8, auc:85.1 | loss:0.474
[56,32] | tst acc:78.2, f1:43.2, auc:84.3 | trn acc:81.4, f1:68.8, auc:85.1 | loss:0.475
[57,380] | tst acc:77.9, f1:42.9, auc:83.3 | trn acc:81.3, f1:68.8, auc:85.0 | loss:0.476
[59,52] | tst acc:77.9, f1:42.9, auc:83.3 | trn acc:81.4, f1:68.9, auc:85.2 | loss:0.475
[60,400] | tst acc:77.7, f1:42.7, auc:83.2 | trn acc:81.5, f1:68.8, auc:85.1 | loss:0.475
[62,72] | tst acc:78.2, f1:43.2, auc:83.1 | trn acc:81.7, f1:69.1, auc:85.2 | loss:0.473
[63,420] | tst acc:78.2, f1:43.2, auc:82.2 | trn acc:81.2, f1:68.7, auc:85.0 | loss:0.477
[65,92] | tst acc:77.9, f1:42.9, auc:83.1 | trn acc:81.6, f1:68.9, auc:85.2 | loss:0.474
[66,440] | tst acc:77.9, f1:42.9, auc:84.5 | trn acc:81.4, f1:68.7, auc:85.0 | loss:0.475
[68,112] | tst acc:78.2, f1:43.2, auc:84.2 | trn acc:81.6, f1:69.1, auc:85.4 | loss:0.474
[69,460] | tst acc:77.9, f1:42.9, auc:82.8 | trn acc:81.4, f1:68.7, auc:85.1 | loss:0.474
Reached final batch of training at iter = 47992
Reached final batch of training at iter = 48000
Epoch 71 finished in 0.00 seconds
[71,4] | tst acc:78.2, f1:43.2, auc:82.8 | trn acc:81.4, f1:68.9, auc:85.0 | loss:0.476
Average epoch runtime: 0.26 seconds
Total training time: 18.65 GPU seconds
SEED: 58475
Loading drug dataset...
Hyperparameters:
Namespace(seed=58475, is_train=True, input_dir='data/input', output_dir='data/output', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=True, init_gene_emb=True, scheduler='onecycle', shuffle=False, omic='exp', use_attention=False, use_cntx_attn=False, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.6, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=False, alpha=0.6, gamma=2.0, adam=False, exp_size=3000, mut_size=1000, cnv_size=1000, omc_size=3000, drg_size=260, train_size=676, test_size=170)
HIDDEN EMBEDDING SIZE: 200
USING RELU
USING PRETRAING EMBEDDINGS
DROPOUT RATE: 0.6
USING HIDDEN LAYER
INITIALIZING SGD OPTIMIZER
Training...
INITIALIZING ONE CYCLE
Batch size: 8
Train dataset size (samples): 676
Batches per epoch: 85
[0,0] | tst acc:49.3, f1:32.2, auc:47.1 | trn acc:50.5, f1:43.5, auc:50.5 | loss:0.885
[1,348] | tst acc:49.5, f1:32.7, auc:46.1 | trn acc:49.7, f1:37.8, auc:49.4 | loss:0.883
[3,20] | tst acc:51.9, f1:36.3, auc:51.6 | trn acc:51.5, f1:38.8, auc:51.5 | loss:0.837
[4,368] | tst acc:58.4, f1:43.3, auc:59.5 | trn acc:54.2, f1:40.7, auc:54.6 | loss:0.785
[6,40] | tst acc:57.5, f1:40.8, auc:57.5 | trn acc:57.1, f1:42.8, auc:57.8 | loss:0.737
[7,388] | tst acc:58.7, f1:41.9, auc:58.9 | trn acc:60.1, f1:45.2, auc:61.1 | loss:0.694
[9,60] | tst acc:63.9, f1:47.6, auc:65.9 | trn acc:63.0, f1:47.2, auc:64.5 | loss:0.655
[10,408] | tst acc:67.5, f1:50.5, auc:69.0 | trn acc:66.0, f1:49.7, auc:67.7 | loss:0.623
[12,80] | tst acc:69.0, f1:52.0, auc:71.2 | trn acc:68.5, f1:52.4, auc:70.5 | loss:0.598
[13,428] | tst acc:72.4, f1:53.4, auc:72.5 | trn acc:71.1, f1:54.7, auc:73.1 | loss:0.574
[15,100] | tst acc:70.7, f1:52.7, auc:74.6 | trn acc:73.1, f1:57.1, auc:75.1 | loss:0.556
[16,448] | tst acc:72.8, f1:52.3, auc:75.5 | trn acc:74.9, f1:59.0, auc:77.1 | loss:0.539
[18,120] | tst acc:75.2, f1:59.3, auc:78.9 | trn acc:76.1, f1:60.4, auc:78.1 | loss:0.530
[19,468] | tst acc:78.4, f1:62.5, auc:79.8 | trn acc:77.3, f1:62.3, auc:79.4 | loss:0.518
[21,140] | tst acc:77.2, f1:60.6, auc:80.2 | trn acc:78.2, f1:63.0, auc:80.2 | loss:0.511
[22,488] | tst acc:76.0, f1:59.7, auc:80.2 | trn acc:78.9, f1:64.2, auc:81.1 | loss:0.503
[24,160] | tst acc:75.0, f1:53.2, auc:81.3 | trn acc:79.4, f1:64.7, auc:81.5 | loss:0.499
[25,508] | tst acc:78.4, f1:61.9, auc:82.0 | trn acc:79.8, f1:65.3, auc:82.0 | loss:0.495
[27,180] | tst acc:79.1, f1:63.3, auc:81.6 | trn acc:80.3, f1:65.9, auc:82.7 | loss:0.489
[28,528] | tst acc:79.1, f1:62.3, auc:81.7 | trn acc:80.4, f1:66.3, auc:82.9 | loss:0.488
[30,200] | tst acc:80.5, f1:66.1, auc:84.1 | trn acc:80.8, f1:66.6, auc:83.3 | loss:0.484
[31,548] | tst acc:81.0, f1:66.9, auc:84.1 | trn acc:81.0, f1:67.1, auc:83.7 | loss:0.481
[33,220] | tst acc:78.8, f1:63.0, auc:83.2 | trn acc:81.0, f1:67.1, auc:83.7 | loss:0.481
[34,568] | tst acc:80.8, f1:65.5, auc:86.2 | trn acc:81.2, f1:67.3, auc:83.9 | loss:0.479
[36,240] | tst acc:81.0, f1:66.4, auc:85.8 | trn acc:81.2, f1:67.3, auc:84.1 | loss:0.478
[37,588] | tst acc:80.5, f1:65.8, auc:85.7 | trn acc:81.2, f1:67.5, auc:84.2 | loss:0.478
[39,260] | tst acc:80.8, f1:65.5, auc:85.6 | trn acc:81.3, f1:67.6, auc:84.3 | loss:0.477
[40,608] | tst acc:80.3, f1:64.7, auc:86.4 | trn acc:81.5, f1:67.8, auc:84.5 | loss:0.476
[42,280] | tst acc:80.8, f1:65.5, auc:85.3 | trn acc:81.8, f1:68.2, auc:84.8 | loss:0.473
[43,628] | tst acc:81.5, f1:67.0, auc:86.1 | trn acc:81.2, f1:67.4, auc:84.4 | loss:0.477
[45,300] | tst acc:80.8, f1:65.8, auc:85.3 | trn acc:81.7, f1:68.1, auc:84.8 | loss:0.473
[46,648] | tst acc:81.5, f1:67.2, auc:85.2 | trn acc:81.3, f1:67.7, auc:84.5 | loss:0.476
[48,320] | tst acc:80.8, f1:65.5, auc:86.3 | trn acc:81.4, f1:67.7, auc:84.6 | loss:0.475
[49,668] | tst acc:80.5, f1:64.9, auc:84.6 | trn acc:81.6, f1:68.1, auc:84.9 | loss:0.473
[51,340] | tst acc:80.8, f1:65.5, auc:85.3 | trn acc:81.7, f1:68.0, auc:85.0 | loss:0.472
[53,12] | tst acc:81.0, f1:66.1, auc:85.5 | trn acc:81.5, f1:68.0, auc:84.8 | loss:0.474
[54,360] | tst acc:80.8, f1:65.5, auc:86.1 | trn acc:81.7, f1:68.1, auc:85.1 | loss:0.472
[56,32] | tst acc:81.0, f1:66.1, auc:86.3 | trn acc:81.3, f1:67.6, auc:84.6 | loss:0.476
[57,380] | tst acc:81.0, f1:66.1, auc:86.7 | trn acc:81.7, f1:68.3, auc:85.0 | loss:0.472
[59,52] | tst acc:81.0, f1:66.1, auc:85.6 | trn acc:81.5, f1:67.8, auc:84.8 | loss:0.474
[60,400] | tst acc:80.8, f1:65.5, auc:86.2 | trn acc:81.7, f1:68.1, auc:85.0 | loss:0.473
[62,72] | tst acc:80.8, f1:65.5, auc:85.9 | trn acc:81.7, f1:68.0, auc:85.0 | loss:0.472
[63,420] | tst acc:81.0, f1:66.1, auc:85.6 | trn acc:81.6, f1:68.2, auc:85.1 | loss:0.473
[65,92] | tst acc:81.0, f1:66.1, auc:85.6 | trn acc:81.6, f1:67.8, auc:84.9 | loss:0.473
[66,440] | tst acc:80.8, f1:65.8, auc:86.3 | trn acc:81.4, f1:67.8, auc:84.8 | loss:0.474
[68,112] | tst acc:80.8, f1:65.8, auc:86.5 | trn acc:81.7, f1:68.2, auc:85.2 | loss:0.472
[69,460] | tst acc:81.0, f1:66.1, auc:85.5 | trn acc:81.4, f1:67.8, auc:84.8 | loss:0.475
Reached final batch of training at iter = 47992
Reached final batch of training at iter = 48000
Epoch 71 finished in 0.00 seconds
[71,4] | tst acc:81.0, f1:66.1, auc:85.4 | trn acc:81.9, f1:68.4, auc:85.2 | loss:0.471
Average epoch runtime: 0.26 seconds
Total training time: 18.59 GPU seconds
SEED: 94707
Loading drug dataset...
Hyperparameters:
Namespace(seed=94707, is_train=True, input_dir='data/input', output_dir='data/output', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=True, init_gene_emb=True, scheduler='onecycle', shuffle=False, omic='exp', use_attention=False, use_cntx_attn=False, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.6, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=False, alpha=0.6, gamma=2.0, adam=False, exp_size=3000, mut_size=1000, cnv_size=1000, omc_size=3000, drg_size=260, train_size=676, test_size=170)
HIDDEN EMBEDDING SIZE: 200
USING RELU
USING PRETRAING EMBEDDINGS
DROPOUT RATE: 0.6
USING HIDDEN LAYER
INITIALIZING SGD OPTIMIZER
Training...
INITIALIZING ONE CYCLE
Batch size: 8
Train dataset size (samples): 676
Batches per epoch: 85
[0,0] | tst acc:53.1, f1:50.6, auc:49.8 | trn acc:51.4, f1:42.5, auc:50.8 | loss:0.872
[1,348] | tst acc:51.1, f1:48.7, auc:52.7 | trn acc:50.3, f1:37.3, auc:49.3 | loss:0.878
[3,20] | tst acc:46.6, f1:44.2, auc:48.5 | trn acc:52.2, f1:38.5, auc:51.5 | loss:0.832
[4,368] | tst acc:57.1, f1:54.8, auc:57.4 | trn acc:54.5, f1:39.9, auc:54.2 | loss:0.783
[6,40] | tst acc:54.8, f1:48.7, auc:61.0 | trn acc:57.3, f1:41.9, auc:57.5 | loss:0.734
[7,388] | tst acc:56.2, f1:48.5, auc:58.1 | trn acc:60.2, f1:44.1, auc:60.8 | loss:0.691
[9,60] | tst acc:60.7, f1:54.7, auc:61.6 | trn acc:63.3, f1:46.6, auc:64.3 | loss:0.652
[10,408] | tst acc:58.8, f1:50.0, auc:64.6 | trn acc:66.1, f1:49.2, auc:67.4 | loss:0.622
[12,80] | tst acc:61.6, f1:51.8, auc:68.3 | trn acc:68.8, f1:51.8, auc:70.5 | loss:0.593
[13,428] | tst acc:58.2, f1:47.5, auc:63.2 | trn acc:71.3, f1:54.5, auc:73.1 | loss:0.571
[15,100] | tst acc:63.6, f1:53.4, auc:70.0 | trn acc:73.4, f1:56.9, auc:75.3 | loss:0.553
[16,448] | tst acc:60.5, f1:50.0, auc:66.6 | trn acc:74.9, f1:58.5, auc:76.9 | loss:0.539
[18,120] | tst acc:61.0, f1:51.4, auc:67.3 | trn acc:76.6, f1:60.7, auc:78.6 | loss:0.525
[19,468] | tst acc:61.0, f1:48.9, auc:67.1 | trn acc:77.6, f1:61.9, auc:79.6 | loss:0.515
[21,140] | tst acc:62.1, f1:51.4, auc:70.1 | trn acc:78.2, f1:62.7, auc:80.2 | loss:0.510
[22,488] | tst acc:63.0, f1:51.3, auc:72.6 | trn acc:78.9, f1:63.8, auc:81.0 | loss:0.503
[24,160] | tst acc:61.6, f1:48.5, auc:71.6 | trn acc:79.7, f1:64.9, auc:81.9 | loss:0.495
[25,508] | tst acc:62.4, f1:49.4, auc:73.2 | trn acc:79.9, f1:65.1, auc:82.1 | loss:0.492
[27,180] | tst acc:62.7, f1:50.7, auc:74.8 | trn acc:80.3, f1:65.8, auc:82.6 | loss:0.489
[28,528] | tst acc:61.9, f1:48.7, auc:71.0 | trn acc:80.6, f1:66.2, auc:82.9 | loss:0.486
[30,200] | tst acc:62.7, f1:50.7, auc:72.0 | trn acc:81.0, f1:66.8, auc:83.5 | loss:0.481
[31,548] | tst acc:61.3, f1:48.3, auc:73.5 | trn acc:80.9, f1:66.8, auc:83.5 | loss:0.482
[33,220] | tst acc:61.6, f1:49.3, auc:72.5 | trn acc:81.2, f1:67.0, auc:83.8 | loss:0.479
[34,568] | tst acc:62.7, f1:50.4, auc:72.5 | trn acc:81.3, f1:67.2, auc:83.9 | loss:0.477
[36,240] | tst acc:61.6, f1:48.5, auc:70.9 | trn acc:81.4, f1:67.5, auc:84.2 | loss:0.475
[37,588] | tst acc:63.3, f1:51.5, auc:73.3 | trn acc:81.2, f1:67.4, auc:84.0 | loss:0.477
[39,260] | tst acc:62.7, f1:49.6, auc:73.5 | trn acc:81.5, f1:67.5, auc:84.3 | loss:0.475
[40,608] | tst acc:62.4, f1:49.8, auc:73.7 | trn acc:81.4, f1:67.6, auc:84.3 | loss:0.476
[42,280] | tst acc:62.4, f1:50.2, auc:72.7 | trn acc:81.7, f1:68.1, auc:84.7 | loss:0.473
[43,628] | tst acc:62.4, f1:49.8, auc:73.5 | trn acc:81.5, f1:67.7, auc:84.5 | loss:0.475
[45,300] | tst acc:62.1, f1:49.6, auc:74.2 | trn acc:81.7, f1:67.9, auc:84.7 | loss:0.473
[46,648] | tst acc:62.7, f1:50.7, auc:74.7 | trn acc:81.6, f1:68.0, auc:84.7 | loss:0.473
[48,320] | tst acc:62.4, f1:50.2, auc:73.0 | trn acc:81.7, f1:68.1, auc:84.8 | loss:0.472
[49,668] | tst acc:62.4, f1:50.2, auc:74.5 | trn acc:81.8, f1:68.1, auc:84.8 | loss:0.472
[51,340] | tst acc:62.7, f1:50.4, auc:75.0 | trn acc:81.5, f1:67.8, auc:84.7 | loss:0.474
[53,12] | tst acc:63.0, f1:50.9, auc:75.4 | trn acc:81.9, f1:68.4, auc:85.0 | loss:0.470
[54,360] | tst acc:62.4, f1:50.2, auc:74.4 | trn acc:81.6, f1:67.9, auc:84.8 | loss:0.473
[56,32] | tst acc:62.4, f1:50.2, auc:75.2 | trn acc:81.7, f1:68.1, auc:84.8 | loss:0.473
[57,380] | tst acc:62.7, f1:50.7, auc:76.5 | trn acc:81.5, f1:68.0, auc:84.8 | loss:0.474
[59,52] | tst acc:62.7, f1:50.7, auc:74.6 | trn acc:81.9, f1:68.2, auc:85.0 | loss:0.470
[60,400] | tst acc:62.7, f1:50.7, auc:74.7 | trn acc:81.8, f1:68.2, auc:85.0 | loss:0.471
[62,72] | tst acc:62.1, f1:49.6, auc:76.0 | trn acc:81.7, f1:68.2, auc:85.0 | loss:0.472
[63,420] | tst acc:62.7, f1:50.7, auc:75.8 | trn acc:81.8, f1:68.0, auc:84.9 | loss:0.471
[65,92] | tst acc:62.4, f1:50.2, auc:74.0 | trn acc:81.7, f1:68.4, auc:85.0 | loss:0.472
[66,440] | tst acc:62.4, f1:50.2, auc:74.1 | trn acc:81.7, f1:68.2, auc:85.0 | loss:0.472
[68,112] | tst acc:62.4, f1:50.2, auc:74.1 | trn acc:81.6, f1:68.0, auc:84.8 | loss:0.473
[69,460] | tst acc:62.7, f1:50.7, auc:75.1 | trn acc:81.7, f1:68.0, auc:84.9 | loss:0.472
Reached final batch of training at iter = 47992
Reached final batch of training at iter = 48000
Epoch 71 finished in 0.00 seconds
[71,4] | tst acc:62.4, f1:50.2, auc:74.3 | trn acc:82.0, f1:68.5, auc:85.3 | loss:0.469
Average epoch runtime: 0.26 seconds
Total training time: 18.77 GPU seconds
