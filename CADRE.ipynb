{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS CELL IF YOU ARE RUNNING IN COLAB\n",
    "# ONLY RUN THIS CELL IF YOU ARE RUNNING IN COLAB\n",
    "import sys\n",
    "import os\n",
    "\n",
    "!git clone https://github.com/Jiminator/CADRE.git\n",
    "!ln -s /content/CADRE/data /content/data\n",
    "!mkdir -p /content/data/output\n",
    "\n",
    "print(os.path.exists(\"data/input/rng.txt\"))\n",
    "print(os.path.exists(\"data/input/exp_emb_gdsc.csv\"))\n",
    "print(os.path.isdir(\"data/output\"))\n",
    "\n",
    "sys.path.append('/content/CADRE')\n",
    "# ONLY RUN THIS CELL IF YOU ARE RUNNING IN COLAB\n",
    "# ONLY RUN THIS CELL IF YOU ARE RUNNING IN COLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Fix Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i9wNvIcr0pt9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "SEED = 5497\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from utils import fill_mask, bool_ext, load_dataset, split_dataset\n",
    "from collabfilter import CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train and Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhjsUCSn0rcK",
    "outputId": "1bd91444-bfa8-4d6c-dbbd-c9d0be729aee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If bool_ext is a custom function, define it or replace it with bool\n",
    "def bool_ext(val):\n",
    "    return val.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "def train(args, pkl_path):\n",
    "    args.is_train = True\n",
    "    args.pkl_path = pkl_path\n",
    "    model = CF(args)\n",
    "    model.build(ptw_ids)\n",
    "\n",
    "    if args.use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "\n",
    "    logs = {'args':args, 'iter':[],\n",
    "            'precision':[], 'recall':[],\n",
    "            'f1score':[], 'accuracy':[], 'auc':[],\n",
    "            'precision_train':[], 'recall_train':[],\n",
    "            'f1score_train':[], 'accuracy_train':[], 'auc_train':[],\n",
    "            'loss':[], 'ptw_ids':ptw_ids}\n",
    "\n",
    "    print(\"Training...\")\n",
    "    logs = model.train(train_set, test_set,\n",
    "        batch_size=args.batch_size,\n",
    "        test_batch_size=args.test_batch_size,\n",
    "        max_iter=args.max_iter,\n",
    "        max_fscore=args.max_fscore,\n",
    "        test_inc_size=args.test_inc_size,\n",
    "        logs=logs\n",
    "    )\n",
    "\n",
    "    labels, msks, preds, tmr, amtr = model.test(test_set, test_batch_size=args.test_batch_size)\n",
    "    labels_train, msks_train, preds_train, tmr_train, amtr_train = model.test_train(train_set, test_batch_size=args.test_batch_size)\n",
    "\n",
    "    logs[\"preds\"] = preds\n",
    "    logs[\"msks\"] = msks\n",
    "    logs[\"labels\"] = labels\n",
    "    logs['tmr'] = tmr\n",
    "    logs['amtr'] = amtr\n",
    "\n",
    "    logs['preds_train'] = preds_train\n",
    "    logs['msks_train'] = msks_train\n",
    "    logs['labels_train'] = labels_train\n",
    "    logs['tmr_train'] = tmr_train\n",
    "    logs['amtr_train'] = amtr_train\n",
    "\n",
    "\n",
    "    if args.store_model:\n",
    "        if not args.pkl_path:\n",
    "            for trial in range(100):\n",
    "                trial_path = os.path.join(args.output_dir, f\"logs{trial}.pkl\")\n",
    "                if not os.path.exists(trial_path):\n",
    "                    print(f\"Auto-saving model to {trial_path}\")\n",
    "                    with open(trial_path, \"wb\") as f:\n",
    "                        pickle.dump(logs, f, protocol=2)\n",
    "                    break\n",
    "        else:\n",
    "            save_path = os.path.join(args.output_dir, args.pkl_path)\n",
    "            if os.path.exists(save_path):\n",
    "                print(f\"Warning: Overwriting existing file {save_path}\")\n",
    "            else:\n",
    "                print(f\"Saving model to {save_path}\")\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                pickle.dump(logs, f, protocol=2)\n",
    "\n",
    "def eval(args, pkl_path):\n",
    "    args.pkl_path = pkl_path\n",
    "    logs = {'args':args, 'iter':[],\n",
    "        'precision':[], 'recall':[],\n",
    "        'f1score':[], 'accuracy':[], 'auc':[],\n",
    "        'precision_train':[], 'recall_train':[],\n",
    "        'f1score_train':[], 'accuracy_train':[], 'auc_train':[],\n",
    "            'loss':[], 'ptw_ids':ptw_ids}\n",
    "\n",
    "    print(f\"Evaluating from saved logs at: {args.pkl_path}\")\n",
    "    with open(args.output_dir + args.pkl_path, \"rb\") as f:\n",
    "        logs = pickle.load(f)\n",
    "    from utils import evaluate_all\n",
    "\n",
    "    preds = logs[\"preds\"]\n",
    "    labels = logs[\"labels\"]\n",
    "    msks = logs[\"msks\"]\n",
    "    precision, recall, f1, acc, auc_roc, auc_pr = evaluate_all(labels, msks, preds)\n",
    "\n",
    "    print(f\"\\nEvaluation Metrics from {args.pkl_path}:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Default Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(seed=5497, is_train=True, eval=False, pkl_path=None, store_model=True, input_dir='data/input', output_dir='data/output/cf/', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=True, init_gene_emb=True, scheduler='onecycle', shuffle=False, omic='exp', use_attention=True, use_cntx_attn=True, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.6, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=False, alpha=0.6, gamma=2.0, adam=False, mlp=False, norm_strategy='None', use_residual=False)\n"
     ]
    }
   ],
   "source": [
    "# Manually define the arguments using argparse.Namespace\n",
    "args = argparse.Namespace(\n",
    "    seed=SEED,\n",
    "    is_train=True,\n",
    "    eval=False,\n",
    "    pkl_path=None,\n",
    "    store_model=True,\n",
    "    input_dir=\"data/input\",\n",
    "    output_dir=\"data/output/cf/\",\n",
    "    repository=\"gdsc\",\n",
    "    drug_id=-1,\n",
    "    use_cuda=True and torch.cuda.is_available(),  # Ensure GPU availability\n",
    "    use_relu=True,\n",
    "    init_gene_emb=True,\n",
    "    scheduler='onecycle',\n",
    "    shuffle=False,\n",
    "    omic=\"exp\",\n",
    "    use_attention=True,\n",
    "    use_cntx_attn=True,\n",
    "    embedding_dim=200,\n",
    "    attention_size=128,\n",
    "    attention_head=8,\n",
    "    hidden_dim_enc=200,\n",
    "    use_hid_lyr=True,\n",
    "    max_iter=int(48000),\n",
    "    max_fscore=-1,\n",
    "    dropout_rate=0.6,\n",
    "    learning_rate=0.3,\n",
    "    weight_decay=3e-4,\n",
    "    batch_size=8,\n",
    "    test_batch_size=8,\n",
    "    test_inc_size=1024,\n",
    "    model_label=\"cntx-attn-gdsc\",\n",
    "    focal=False,\n",
    "    alpha=0.6,\n",
    "    gamma=2.0,\n",
    "    adam=False,\n",
    "    mlp=False,\n",
    "    norm_strategy='None',\n",
    "    use_residual=False\n",
    ")\n",
    "\n",
    "\n",
    "# Now, args is ready to use just like it would be from argparse.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKa0B351AoO2",
    "outputId": "f4d7d2c6-cec2-4abf-df7a-ebef27f9c014",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading drug dataset...\n",
      "Hyperparameters:\n",
      "Namespace(seed=5497, is_train=True, eval=False, pkl_path=None, store_model=True, input_dir='data/input', output_dir='data/output/cf/', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=True, init_gene_emb=True, scheduler='onecycle', shuffle=False, omic='exp', use_attention=True, use_cntx_attn=True, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.6, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=False, alpha=0.6, gamma=2.0, adam=False, mlp=False, norm_strategy='None', use_residual=False, exp_size=3000, mut_size=1000, cnv_size=1000, omc_size=3000, drg_size=260, train_size=676, test_size=170)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading drug dataset...\")\n",
    "dataset, ptw_ids = load_dataset(input_dir=args.input_dir, repository=args.repository, drug_id=args.drug_id)\n",
    "train_set, test_set = split_dataset(dataset, ratio=0.8)\n",
    "\n",
    "# replace tgt in train_set\n",
    "train_set['tgt'], train_set['msk'] = fill_mask(train_set['tgt'], train_set['msk'])\n",
    "\n",
    "args.exp_size = dataset['exp_bin'].shape[1]\n",
    "args.mut_size = dataset['mut_bin'].shape[1]\n",
    "args.cnv_size = dataset['cnv_bin'].shape[1]\n",
    "\n",
    "if args.omic == 'exp':\n",
    "  args.omc_size = args.exp_size\n",
    "elif args.omic == 'mut':\n",
    "  args.omc_size = args.mut_size\n",
    "elif args.omic == 'cnv':\n",
    "  args.omc_size = args.cnv_size\n",
    "\n",
    "args.drg_size = dataset['tgt'].shape[1]\n",
    "args.train_size = len(train_set['tmr'])\n",
    "args.test_size = len(test_set['tmr'])\n",
    "\n",
    "print(\"Hyperparameters:\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Original CADRE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cm6Dg139Arla",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING RELU\n",
      "USING PRETRAING EMBEDDINGS\n",
      "DROPOUT RATE: 0.6\n",
      "USING HIDDEN LAYER\n",
      "USING SELF ATTENTION\n",
      "USING CONTEXTUAL ATTENTION\n",
      "INITIALIZING SGD OPTIMIZER\n",
      "Training...\n",
      "INITIALIZING ONE CYCLE\n",
      "Training with optimizer: SGD\n",
      "Scheduler: onecycle\n",
      "Batch size: 8\n",
      "Train dataset size (samples): 676\n",
      "Batches per epoch: 85\n",
      "[0,0] | tst acc:50.3, f1:40.6, auc:52.0 | trn acc:51.1, f1:40.9, auc:53.2 | loss:4.269\n",
      "[1,348] | tst acc:59.4, f1:45.9, auc:61.5 | trn acc:55.8, f1:44.6, auc:58.1 | loss:2.945\n",
      "[3,20] | tst acc:62.4, f1:48.1, auc:64.0 | trn acc:63.0, f1:48.8, auc:62.9 | loss:0.980\n",
      "[4,368] | tst acc:62.5, f1:47.4, auc:64.1 | trn acc:64.0, f1:49.5, auc:65.2 | loss:0.696\n",
      "[6,40] | tst acc:64.4, f1:49.1, auc:67.1 | trn acc:65.3, f1:50.7, auc:67.3 | loss:0.652\n",
      "[7,388] | tst acc:66.6, f1:50.5, auc:69.0 | trn acc:67.6, f1:52.5, auc:70.5 | loss:0.614\n",
      "[9,60] | tst acc:68.5, f1:52.0, auc:70.9 | trn acc:69.6, f1:54.3, auc:72.7 | loss:0.591\n",
      "[10,408] | tst acc:70.1, f1:53.5, auc:72.8 | trn acc:71.6, f1:56.2, auc:74.7 | loss:0.570\n",
      "[12,80] | tst acc:71.4, f1:54.5, auc:74.0 | trn acc:73.5, f1:57.9, auc:76.5 | loss:0.550\n",
      "[13,428] | tst acc:72.7, f1:55.9, auc:75.2 | trn acc:74.6, f1:59.1, auc:77.5 | loss:0.538\n",
      "[15,100] | tst acc:73.7, f1:56.8, auc:76.1 | trn acc:75.8, f1:60.4, auc:78.8 | loss:0.521\n",
      "[16,448] | tst acc:74.1, f1:57.0, auc:76.7 | trn acc:76.7, f1:61.3, auc:79.6 | loss:0.511\n",
      "[18,120] | tst acc:74.9, f1:58.2, auc:77.4 | trn acc:77.4, f1:62.4, auc:80.3 | loss:0.501\n",
      "[19,468] | tst acc:75.2, f1:58.6, auc:78.2 | trn acc:78.2, f1:63.2, auc:81.1 | loss:0.490\n",
      "[21,140] | tst acc:76.0, f1:59.6, auc:78.7 | trn acc:78.4, f1:63.6, auc:81.4 | loss:0.486\n",
      "[22,488] | tst acc:76.0, f1:59.5, auc:78.9 | trn acc:79.1, f1:64.4, auc:82.1 | loss:0.476\n",
      "[24,160] | tst acc:76.5, f1:60.3, auc:79.0 | trn acc:79.1, f1:64.5, auc:82.1 | loss:0.474\n",
      "[25,508] | tst acc:76.6, f1:60.2, auc:79.7 | trn acc:79.5, f1:65.0, auc:82.6 | loss:0.469\n",
      "[27,180] | tst acc:76.6, f1:59.7, auc:79.7 | trn acc:79.7, f1:65.2, auc:82.9 | loss:0.464\n",
      "[28,528] | tst acc:77.1, f1:60.8, auc:80.3 | trn acc:80.0, f1:65.9, auc:83.2 | loss:0.462\n",
      "[30,200] | tst acc:77.1, f1:60.9, auc:80.3 | trn acc:80.2, f1:66.0, auc:83.6 | loss:0.455\n",
      "[31,548] | tst acc:77.2, f1:61.2, auc:80.7 | trn acc:80.1, f1:66.0, auc:83.5 | loss:0.457\n",
      "[33,220] | tst acc:77.5, f1:61.3, auc:80.9 | trn acc:81.0, f1:66.9, auc:84.5 | loss:0.440\n",
      "[34,568] | tst acc:77.3, f1:61.1, auc:80.9 | trn acc:80.1, f1:66.2, auc:83.7 | loss:0.456\n",
      "[36,240] | tst acc:77.5, f1:61.6, auc:81.2 | trn acc:80.8, f1:66.8, auc:84.2 | loss:0.447\n",
      "[37,588] | tst acc:77.6, f1:61.5, auc:81.3 | trn acc:80.9, f1:67.0, auc:84.5 | loss:0.442\n",
      "[39,260] | tst acc:77.8, f1:61.8, auc:81.5 | trn acc:81.0, f1:67.4, auc:84.7 | loss:0.441\n",
      "[40,608] | tst acc:77.8, f1:61.9, auc:81.5 | trn acc:80.9, f1:67.2, auc:84.6 | loss:0.443\n",
      "[42,280] | tst acc:77.8, f1:61.8, auc:81.6 | trn acc:81.2, f1:67.5, auc:85.0 | loss:0.437\n",
      "[43,628] | tst acc:78.0, f1:62.2, auc:81.8 | trn acc:81.0, f1:67.3, auc:84.7 | loss:0.441\n",
      "[45,300] | tst acc:78.0, f1:62.3, auc:82.1 | trn acc:81.3, f1:67.8, auc:85.2 | loss:0.433\n",
      "[46,648] | tst acc:77.9, f1:62.1, auc:82.0 | trn acc:81.3, f1:67.7, auc:85.1 | loss:0.435\n",
      "[48,320] | tst acc:78.1, f1:62.4, auc:82.0 | trn acc:81.3, f1:67.8, auc:85.3 | loss:0.432\n",
      "[49,668] | tst acc:78.2, f1:62.8, auc:82.3 | trn acc:81.4, f1:67.8, auc:85.4 | loss:0.430\n",
      "[51,340] | tst acc:78.2, f1:63.1, auc:82.3 | trn acc:81.4, f1:68.2, auc:85.6 | loss:0.430\n",
      "[53,12] | tst acc:78.2, f1:62.4, auc:82.3 | trn acc:81.5, f1:68.1, auc:85.5 | loss:0.429\n",
      "[54,360] | tst acc:78.4, f1:63.1, auc:82.4 | trn acc:81.6, f1:68.4, auc:85.7 | loss:0.427\n",
      "[56,32] | tst acc:78.4, f1:62.9, auc:82.6 | trn acc:81.5, f1:68.2, auc:85.8 | loss:0.426\n",
      "[57,380] | tst acc:78.5, f1:63.1, auc:82.7 | trn acc:81.6, f1:68.3, auc:85.8 | loss:0.425\n",
      "[59,52] | tst acc:78.6, f1:63.6, auc:82.8 | trn acc:81.7, f1:68.7, auc:86.0 | loss:0.423\n",
      "[60,400] | tst acc:78.5, f1:63.7, auc:82.9 | trn acc:81.6, f1:68.6, auc:86.0 | loss:0.424\n",
      "[62,72] | tst acc:78.5, f1:63.4, auc:83.0 | trn acc:81.8, f1:68.7, auc:86.2 | loss:0.419\n",
      "[63,420] | tst acc:78.6, f1:63.6, auc:83.0 | trn acc:81.7, f1:68.6, auc:86.0 | loss:0.423\n",
      "[65,92] | tst acc:78.7, f1:63.8, auc:83.0 | trn acc:82.0, f1:69.0, auc:86.5 | loss:0.415\n",
      "[66,440] | tst acc:78.8, f1:64.2, auc:83.3 | trn acc:81.6, f1:68.8, auc:86.1 | loss:0.424\n",
      "[68,112] | tst acc:78.8, f1:64.0, auc:83.1 | trn acc:82.0, f1:69.2, auc:86.4 | loss:0.416\n",
      "[69,460] | tst acc:78.7, f1:63.8, auc:83.0 | trn acc:81.7, f1:68.9, auc:86.2 | loss:0.420\n",
      "Reached final batch of training at iter = 47992\n",
      "Reached final batch of training at iter = 48000\n",
      "Epoch 71 finished in 0.09 seconds\n",
      "[71,4] | tst acc:78.6, f1:63.7, auc:83.2 | trn acc:82.0, f1:69.2, auc:86.4 | loss:0.416\n",
      "Average epoch runtime: 8.22 seconds\n",
      "Total training time: 591.55 GPU seconds\n",
      "Saving model to data/output/cf/default.pkl\n"
     ]
    }
   ],
   "source": [
    "train(args, \"default.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating from saved logs at: default.pkl\n",
      "\n",
      "Evaluation Metrics from default.pkl:\n",
      "Accuracy: 0.7873\n",
      "F1 Score: 0.6382\n",
      "Precision: 0.6770\n",
      "Recall: 0.6035\n",
      "AUC-ROC: 0.8319\n",
      "AUC-PR: 0.6899\n"
     ]
    }
   ],
   "source": [
    "eval(args, \"default.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Improved CADRE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TG38gxrAvWZ",
    "outputId": "d3b419c7-179d-4725-9919-432f514b5c35",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(seed=5497, is_train=True, eval=False, pkl_path='default.pkl', store_model=True, input_dir='data/input', output_dir='data/output/cf/', repository='gdsc', drug_id=-1, use_cuda=True, use_relu=False, init_gene_emb=True, scheduler='cosine', shuffle=False, omic='exp', use_attention=True, use_cntx_attn=True, embedding_dim=200, attention_size=128, attention_head=8, hidden_dim_enc=200, use_hid_lyr=True, max_iter=48000, max_fscore=-1, dropout_rate=0.0, learning_rate=0.3, weight_decay=0.0003, batch_size=8, test_batch_size=8, test_inc_size=1024, model_label='cntx-attn-gdsc', focal=True, alpha=0.7, gamma=2.0, adam=False, mlp=False, norm_strategy='None', use_residual=True, exp_size=3000, mut_size=1000, cnv_size=1000, omc_size=3000, drg_size=260, train_size=676, test_size=170)\n"
     ]
    }
   ],
   "source": [
    "args.dropout_rate = 0.0\n",
    "args.use_relu = False\n",
    "args.focal = True\n",
    "args.alpha = 0.7\n",
    "args.scheduler = 'cosine'\n",
    "args.use_residual = True\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOnjf_TcAwZr",
    "outputId": "ce090406-be16-406b-f390-07e2580ccea6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING RESIDUAL CONNECTION\n",
      "USING PRETRAING EMBEDDINGS\n",
      "DROPOUT RATE: 0.0\n",
      "USING HIDDEN LAYER\n",
      "USING SELF ATTENTION\n",
      "USING CONTEXTUAL ATTENTION\n",
      "INITIALIZING SGD OPTIMIZER\n",
      "INITIALIZING COSINE SCHEDULER\n",
      "USING FOCAL LOSS\n",
      "GAMMA: 2.0\n",
      "ALPHA: tensor(0.7000)\n",
      "Training...\n",
      "Training with optimizer: SGD\n",
      "Scheduler: cosine\n",
      "Batch size: 8\n",
      "Train dataset size (samples): 676\n",
      "Batches per epoch: 85\n",
      "[0,0] | tst acc:51.2, f1:41.3, auc:53.5 | trn acc:52.6, f1:41.1, auc:55.7 | loss:1.543\n",
      "[1,348] | tst acc:67.8, f1:58.3, auc:76.2 | trn acc:69.0, f1:58.9, auc:74.4 | loss:0.372\n",
      "[3,20] | tst acc:73.6, f1:62.6, auc:79.5 | trn acc:73.6, f1:63.7, auc:81.1 | loss:0.071\n",
      "[4,368] | tst acc:73.4, f1:63.7, auc:80.8 | trn acc:75.7, f1:66.0, auc:83.2 | loss:0.058\n",
      "[6,40] | tst acc:71.6, f1:63.5, auc:81.3 | trn acc:76.5, f1:67.4, auc:84.3 | loss:0.055\n",
      "[7,388] | tst acc:75.8, f1:64.9, auc:82.1 | trn acc:77.3, f1:68.1, auc:85.0 | loss:0.053\n",
      "[9,60] | tst acc:75.2, f1:65.1, auc:82.4 | trn acc:77.3, f1:68.1, auc:85.1 | loss:0.053\n",
      "[10,408] | tst acc:74.8, f1:65.1, auc:82.4 | trn acc:77.7, f1:68.6, auc:85.5 | loss:0.052\n",
      "[12,80] | tst acc:75.4, f1:65.7, auc:83.0 | trn acc:78.2, f1:69.1, auc:86.1 | loss:0.051\n",
      "[13,428] | tst acc:74.7, f1:65.8, auc:83.3 | trn acc:78.5, f1:69.4, auc:86.1 | loss:0.051\n",
      "[15,100] | tst acc:74.0, f1:65.5, auc:83.2 | trn acc:78.6, f1:69.6, auc:86.3 | loss:0.051\n",
      "[16,448] | tst acc:78.2, f1:65.9, auc:83.5 | trn acc:78.5, f1:69.4, auc:86.4 | loss:0.051\n",
      "[18,120] | tst acc:74.4, f1:65.9, auc:83.5 | trn acc:78.7, f1:69.8, auc:86.4 | loss:0.051\n",
      "[19,468] | tst acc:76.9, f1:66.4, auc:83.6 | trn acc:79.0, f1:69.7, auc:86.7 | loss:0.050\n",
      "[21,140] | tst acc:76.9, f1:66.4, auc:83.7 | trn acc:79.0, f1:70.0, auc:86.7 | loss:0.050\n",
      "[22,488] | tst acc:76.9, f1:66.2, auc:83.5 | trn acc:78.7, f1:69.6, auc:86.7 | loss:0.050\n",
      "[24,160] | tst acc:75.8, f1:66.4, auc:83.5 | trn acc:78.8, f1:69.6, auc:86.5 | loss:0.050\n",
      "[25,508] | tst acc:76.8, f1:66.5, auc:83.7 | trn acc:79.0, f1:69.9, auc:86.7 | loss:0.050\n",
      "[27,180] | tst acc:77.7, f1:65.9, auc:83.5 | trn acc:78.7, f1:69.7, auc:86.8 | loss:0.050\n",
      "[28,528] | tst acc:76.6, f1:66.5, auc:83.8 | trn acc:78.8, f1:69.9, auc:86.6 | loss:0.051\n",
      "[30,200] | tst acc:74.8, f1:66.0, auc:83.4 | trn acc:79.0, f1:69.7, auc:86.8 | loss:0.050\n",
      "[31,548] | tst acc:75.1, f1:66.1, auc:83.7 | trn acc:78.9, f1:70.1, auc:86.7 | loss:0.050\n",
      "[33,220] | tst acc:78.3, f1:65.8, auc:83.8 | trn acc:79.6, f1:70.2, auc:87.3 | loss:0.049\n",
      "[34,568] | tst acc:76.3, f1:66.3, auc:83.6 | trn acc:78.1, f1:69.6, auc:86.3 | loss:0.051\n",
      "[36,240] | tst acc:74.0, f1:65.8, auc:83.7 | trn acc:79.3, f1:70.1, auc:86.8 | loss:0.050\n",
      "[37,588] | tst acc:77.1, f1:66.7, auc:83.8 | trn acc:79.1, f1:69.9, auc:86.9 | loss:0.050\n",
      "[39,260] | tst acc:77.0, f1:67.0, auc:83.9 | trn acc:79.3, f1:70.5, auc:87.2 | loss:0.049\n",
      "[40,608] | tst acc:75.4, f1:66.4, auc:83.9 | trn acc:79.3, f1:70.3, auc:86.9 | loss:0.050\n",
      "[42,280] | tst acc:76.0, f1:66.6, auc:83.9 | trn acc:79.2, f1:70.2, auc:87.0 | loss:0.050\n",
      "[43,628] | tst acc:77.0, f1:66.8, auc:83.9 | trn acc:78.9, f1:69.9, auc:86.8 | loss:0.050\n",
      "[45,300] | tst acc:75.6, f1:66.4, auc:83.9 | trn acc:79.5, f1:70.4, auc:87.1 | loss:0.049\n",
      "[46,648] | tst acc:77.0, f1:66.5, auc:83.8 | trn acc:79.4, f1:70.2, auc:86.9 | loss:0.050\n",
      "[48,320] | tst acc:76.7, f1:66.9, auc:84.0 | trn acc:79.5, f1:70.5, auc:87.1 | loss:0.050\n",
      "[49,668] | tst acc:75.4, f1:66.5, auc:83.9 | trn acc:79.8, f1:70.4, auc:87.0 | loss:0.050\n",
      "[51,340] | tst acc:75.0, f1:66.2, auc:83.9 | trn acc:79.5, f1:70.7, auc:87.2 | loss:0.049\n",
      "[53,12] | tst acc:77.6, f1:66.6, auc:84.0 | trn acc:79.0, f1:69.8, auc:86.9 | loss:0.050\n",
      "[54,360] | tst acc:76.0, f1:66.7, auc:84.0 | trn acc:79.6, f1:70.5, auc:87.2 | loss:0.049\n",
      "[56,32] | tst acc:76.1, f1:66.8, auc:84.0 | trn acc:79.6, f1:70.4, auc:87.1 | loss:0.049\n",
      "[57,380] | tst acc:77.1, f1:66.7, auc:84.0 | trn acc:79.4, f1:70.2, auc:87.1 | loss:0.050\n",
      "[59,52] | tst acc:76.5, f1:66.8, auc:84.0 | trn acc:79.7, f1:70.8, auc:87.3 | loss:0.049\n",
      "[60,400] | tst acc:76.4, f1:66.8, auc:84.0 | trn acc:79.4, f1:70.5, auc:87.1 | loss:0.050\n",
      "[62,72] | tst acc:76.6, f1:66.9, auc:84.0 | trn acc:79.8, f1:70.7, auc:87.3 | loss:0.049\n",
      "[63,420] | tst acc:76.6, f1:66.8, auc:84.0 | trn acc:79.3, f1:70.3, auc:87.0 | loss:0.050\n",
      "[65,92] | tst acc:76.6, f1:66.8, auc:84.0 | trn acc:80.0, f1:70.8, auc:87.5 | loss:0.049\n",
      "[66,440] | tst acc:76.5, f1:66.9, auc:84.0 | trn acc:79.7, f1:70.7, auc:87.1 | loss:0.050\n",
      "[68,112] | tst acc:76.5, f1:66.8, auc:84.0 | trn acc:79.7, f1:70.6, auc:87.4 | loss:0.049\n",
      "[69,460] | tst acc:76.5, f1:66.8, auc:84.0 | trn acc:79.7, f1:70.8, auc:87.3 | loss:0.049\n",
      "Reached final batch of training at iter = 47992\n",
      "Reached final batch of training at iter = 48000\n",
      "Epoch 71 finished in 0.09 seconds\n",
      "[71,4] | tst acc:76.5, f1:66.8, auc:84.0 | trn acc:79.7, f1:70.6, auc:87.3 | loss:0.049\n",
      "Average epoch runtime: 8.71 seconds\n",
      "Total training time: 626.78 GPU seconds\n",
      "Saving model to data/output/cf/final.pkl\n"
     ]
    }
   ],
   "source": [
    "train(args, \"final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating from saved logs at: final.pkl\n",
      "\n",
      "Evaluation Metrics from final.pkl:\n",
      "Accuracy: 0.7652\n",
      "F1 Score: 0.6682\n",
      "Precision: 0.5957\n",
      "Recall: 0.7608\n",
      "AUC-ROC: 0.8398\n",
      "AUC-PR: 0.6981\n"
     ]
    }
   ],
   "source": [
    "eval(args, \"final.pkl\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-cadre]",
   "language": "python",
   "name": "conda-env-miniconda3-cadre-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
